[{"content":"创建一个新的conda环境，并在这个环境中使用 poetry。 这是为了防止conda环境和poetry环境之间有冲突，或者因为全局系统级别的Python和包影响项目。\n步骤：\n创建conda环境（此处的myenv是环境名，3.11是你需要的Python版本）：\n1 conda create -n myenv python=3.11 激活这个conda环境：\n1 conda activate myenv 确认你正在使用conda环境中的Python。在终端输入以下命令，查看python路径：\n1 which python 你应该可以看到一个指向你刚创建的conda环境的路径。\n现在，你应该可以在你的conda环境中安装和使用 poetry 了。可以通过以下命令来安装 poetry：\n1 pip install poetry 当我们在conda环境中启动了poetry后，可以创建一个新的poetry项目，或切换到已有的poetry项目目录下，然后使用 poetry install 安装项目的依赖。由于你是在conda环境中启动的 poetry，所以依赖会被安装在当前的conda环境中。 请注意，使用这种方式，conda会负责管理Python和二进制依赖，而poetry则负责管理Python包。\n最后，附赠一份poetry项目常用的镜像构建脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 FROM python:3.11-bookworm as builder WORKDIR /app COPY pyproject.toml poetry.lock /app/ ENV POETRY_VIRTUALENVS_CREATE false RUN pip3 install pip --upgrade \u0026amp;\u0026amp; pip3 install poetry --upgrade \u0026amp;\u0026amp; poetry install --no-root --only main FROM python:3.11-slim-bookworm WORKDIR /app COPY --from=builder /usr/local/lib/python3.11 /usr/local/lib/python3.11 COPY --from=builder /usr/local/bin/ /usr/local/bin/ COPY . /app EXPOSE 8080 # Run the application when the container launches CMD [\u0026#34;python\u0026#34;, \u0026#34;main.py\u0026#34;] ","date":"2023-09-11T18:07:52+08:00","permalink":"https://www.lingcoder.com/p/conda-and-poetry-usage/","title":"Conda和poetry搭配使用"},{"content":"2023年元旦归来的第一件事，决定再次把博客搞起来。为什么是“又”呢，因为这样的事情做了不下两次了，每次都以荒废告终。 慢慢把以前的文章移过来，希望这次能坚持下去。。。\n纸上得来终觉浅，绝知此事要躬行\n","date":"2023-01-03T15:00:00+08:00","image":"https://www.lingcoder.com/p/first-blog/cover_hub86aaedc28a2c526e4ba7df6109c2256_777177_120x120_fill_box_smart1_3.png","permalink":"https://www.lingcoder.com/p/first-blog/","title":"又见第一篇博客"},{"content":"安装 Oracle JDK Webupd8 Team维护一个PPA存储库，其中包含适用于所有当前Ubuntu版本的Oracle Java 8安装程序脚本。\n打开终端并运行命令添加 PPA： 1 sudo add-apt-repository ppa:webupd8team/java ​\t输入密码（输入时不会显示星号），然后按Enter键继续。\n然后运行命令安装Java 8安装程序并在提示时接受许可证： 1 sudo apt-get install oracle-java8-installer 安装完成后，Oracle Java 8应自动设置为默认值。 如果没有，运行命令：\n1 sudo apt-get install oracle-java8-set-default 卸载：\n移除PPA软件包总是很容易，只需打开终端并运行命令即可：\n1 sudo apt-get remove --autoremove oracle-java8-installer oracle-java10-installer 安装 Open JDK 添加 ppa 源 1 sudo add-apt-repository ppa:openjdk-r/ppa 升级系统资源包并安装openjdk1.8： 1 2 3 sudo apt-get update sudo apt-get install openjdk-8-jdk 在多个JDK版本中切换JDK 1 2 sudo update-alternatives --config java sudo update-alternatives --config javac 检查JDK版本： 1 java -version ","date":"2020-06-18T07:59:17+08:00","permalink":"https://www.lingcoder.com/p/install-jdk8-on-ubuntu1804/","title":"在Ubuntu18.04中安装JDK8"},{"content":"Redis安装和高可用集群搭建 安装步骤 官网下载:https://redis.io/download\nCentOS 7 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 安装 GCC GC++ yum -y install gcc yum -y install gcc-c++ yum -y install tcl # 下载,解压至/usr/local,切换目录 wget http://download.redis.io/releases/redis-5.0.5.tar.gz tar -zxvf redis-5.0.5.tar.gz -C /usr/local cd /usr/local cd redis-5.0.5 # 编译安装 make make PREFIX=/usr/local/redis-cluster install Ubunt 18.04 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 安装 GCC GC++ sudo apt update sudo apt install make sudo apt install tcl sudo apt install gcc # 下载,解压至/usr/local,切换目录 wget http://download.redis.io/releases/redis-5.0.5.tar.gz tar -zxvf redis-5.0.5.tar.gz -C /usr/local cd /usr/local cd redis-5.0.5 # 编译安装 make make PREFIX=/usr/local/redis-cluster install 复制配置文件到 /usr/local/redis-cluster/bin 目录，修改的 redis.conf 配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # ip绑定 # bind 192.168.137.200 # 是否限制ip protected-mode no # 是否需要密码 # requirepass xxxxxx # 启动端口 port 6379 # 后台启动 daemonize yes # 是否开启持久化 # save \u0026#34;\u0026#34; stop-writes-on-bgsave-error yes # 数据目录 dir ../6379/data/ replica-read-only yes # 最大内存限制 # maxmemory \u0026lt;bytes\u0026gt; # 内存淘汰策略 # 当超出最大内存时触发 # volatile-lru: 仅限设置了 expire 的部分; 优先删除最近最少使用(Least recently used ,LRU) 的 key。 # allkeys-lru -\u0026gt; 优先删除最近最少使用 # volatile-lfu -\u0026gt; 仅限设置了 expire 的部分; 优先删除最近使用频率最低(Least Frequently Used) # allkeys-lfu -\u0026gt; 优先删除最近使用频率最低 # volatile-random: 仅限设置了 expire 的部分; 随机删除一部分 key。 # allkeys-random: 所有key通用; 随机删除一部分 key。 # volatile-ttl: 仅限设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key # noeviction -\u0026gt; 不删除策略, 超出最大内存限制直接返回错误信息。 # # LRU LFU TTL 都是近似时间,非精确值 maxmemory-policy volatile-lru appendonly yes # 是否开启集群 cluster-enabled yes cluster-config-file nodes-6379.conf 开始运行 1 2 3 4 5 6 7 8 9 10 11 # 切换到目录 cd /usr/local/redis-cluster/bin # 指定配置文件启动 ./redis-server ../6379/redis.conf #验证启动是否成功 ps -ef | grep redis # 进入redis客户端 ./redis-cli -p 6379 退出服务\n1 2 3 4 5 kill redis-server kill 进程号 src/redis-cli shutdown 集群搭建 最低 3主 或者 3主3从\n按照生产3台机器部署,每台2个实例。 可以把上面redis.conf 文件复制一份，涉及端口 6379 的地方修改端口为6380。另外2台同样操作。\n举例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 192.168.137.101 cd /usr/local/redis-cluster/bin ./redis-server ../6379/redis.conf ./redis-server ../6380/redis.conf # 192.168.137.200 cd /usr/local/redis-cluster/bin ./redis-server ../6379/redis.conf ./redis-server ../6380/redis.conf # 192.168.137.201 cd /usr/local/redis-cluster/bin ./redis-server ../6379/redis.conf ./redis-server ../6380/redis.conf 用 redis-cli 创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现)\n1 2 cd /usr/local/redis-cluster/bin/ ./redis-cli --cluster create --cluster-replicas 1 192.168.137.101:6379 192.168.137.101:6380 192.168.137.200:6379 192.168.137.200:6380 192.168.137.201:6379 192.168.137.201:6380 如果之前redis集群给全部停掉了，这时候再建立集群时，会出现如下的情况\n1 [ERR] Node 192.168.5.100:8001 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0. 这个时候需要将每个节点下的这几个文件给删掉（测试情况删掉，实际应用不要删，这是备份文件以及节点信息，按实际的情况进行处理）：\n1 appendonly.aof dump.rdb nodes-8001.conf 集群连接 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 cd /usr/local/redis-cluster/bin ./redis-cli -c -h 192.168.137.101 -p 6379 # 查看集群信息 cluster info # 查看节点信息 cluster nodes # 逐个进行关闭 ./redis-cli -a xxx -c -h 192.168.137.101 -p 6379 shutdown ./redis-cli -a xxx -c -h 192.168.137.101 -p 6380 shutdown ./redis-cli -a xxx -c -h 192.168.137.200 -p 6379 shutdown ./redis-cli -a xxx -c -h 192.168.137.200 -p 6380 shutdown ./redis-cli -a xxx -c -h 192.168.137.201 -p 6379 shutdown ./redis-cli -a xxx -c -h 192.168.137.201 -p 6380 shutdown ","date":"2020-01-13T20:48:02+08:00","image":"https://www.lingcoder.com/p/redis-install-and-config/cover_hu688250e219bb0ee92b57761c16822282_56919_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.lingcoder.com/p/redis-install-and-config/","title":"Redis安装和高可用集群搭建"},{"content":"内网环境集群主机的时间同步 场景描述 内网主机之间时间不一致，需要作同步；主机多数不能连接外网，只有极少数几台能连接外网 系统环境 centos7 root权限 实施方案 内网中一台主机A (如172.16.59.25)与外网互通，通过外网 NTP 服务器同步时间\n主机A对内网提供 NTP 服务\n内网其他机器通过主机A进行对时\n实施过程 主机A设置 1 2 3 4 5 6 7 8 9 10 # 安装NTP软件 # 方式1 yum -y install ntp # 方式2（严格按照顺序autogen-\u0026gt;ntpdate-\u0026gt;ntp） rpm -hiv autogen-libopts-5.18-5.el7.x86_64.rpm rpm -hiv ntpdate-4.2.6p5-18.el7.centos.x86_64.rpm rpm -hiv ntp-4.2.6p5-18.el7.centos.x86_64.rpm # 编辑NTP配置 vim /etc/ntp.conf ntp.conf 配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 driftfile /var/lib/ntp/drift # 默认拒绝客户端所有操作 restrict default kod notrap nomodify nopeer noquery # 允许本地操作 restrict 127.0.0.1 restrict ::1 # 允许该网段同步时间，但不可修改NTP服务器时间 restrict 172.16.59.0 mask 255.255.255.0 nomodify # 用于NTPD的上级服务器、本机时钟的同步,以及时钟的层次stratum server cn.ntp.org.cn prefer server edu.ntp.org.cn iburst # 本机时间兜底 server 127.127.1.0 fudge 127.127.1.0 stratum 8 includefile /etc/ntp/crypto/pw keys /etc/ntp/keys disable monitor 1 2 # 编辑 ntpd 文件 vim /etc/sysconfig/ntpd ntpd 文件修改如下\n1 2 3 OPTIONS=\u0026#34;-u ntp:ntp -p /var/run/ntpd.pid\u0026#34; # BIOS时间也会跟随改变 SYNC_HWCLOCK=yes 1 2 3 4 5 6 7 8 # 查看状态 systemctl status ntpd.service ntpstat # 重启服务 systemctl restart ntpd.service # 开机启动 systemctl enable ntpd.service 其他主机设置 1 2 3 4 5 6 7 8 9 10 # 安装 ntpdate 软件 # 方式1 yum -y install ntp # 方式2（严格按照顺序autogen-\u0026gt;ntpdate-\u0026gt;ntp） rpm -hiv autogen-libopts-5.18-5.el7.x86_64.rpm rpm -hiv ntpdate-4.2.6p5-18.el7.centos.x86_64.rpm rpm -hiv ntp-4.2.6p5-18.el7.centos.x86_64.rpm # 编辑配置文件 vi /etc/ntp.conf ntp.conf配置如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 driftfile /var/lib/ntp/drift # 默认拒绝客户端所有操作 restrict default kod notrap nomodify nopeer noquery # 禁止本身的server # server cn.ntp.org.cn prefer # server edu.ntp.org.cn iburst restrict 172.16.59.25 restrict 127.0.0.1 restrict ::1 server 172.16.59.25 # server 127.127.1.0 # fudge 127.127.1.0 stratum 10 includefile /etc/ntp/crypto/pw keys /etc/ntp/keys disable monitor 1 2 # 编辑 ntpd 文件 vim /etc/sysconfig/ntpd ntpd 文件修改如下\n1 2 3 OPTIONS=\u0026#34;-u ntp:ntp -p /var/run/ntpd.pid\u0026#34; # BIOS时间也会跟随改变 SYNC_HWCLOCK=yes 1 2 3 systemctl restart ntpd.service # 开机启动 systemctl enable ntpd.service 过程总结 可能失败原因及分析 NTP 服务刚启动后，客户端无法同步时间，需等待几分钟才可以\n关闭或者设置防火墙，允许123端口\n网络上存在多个 NTP 服务器时，客户端切换同步源后需要重启\n如果本机与 NTP 服务器时间误差超过1000s，则同步失败。可以按照下面命令解决。\n1 2 3 4 5 6 # 更改时区为中国 timedatectl set-timezone \u0026#34;Asia/Shanghai\u0026#34; # 与外网或者主机A同步一次时间 ntpdate cn.ntp.org.cn #主机A的时间同步 ntpdate 主机A的IP # 内网其他机器的时间同步 # 注意 ntpdate 的缺点 stratum 的概念 顶层是1，值为0时表示层数不明，层的值是累加的，比如 NTP 授时方向是 A -\u0026gt; B -\u0026gt; C，假设 A 的层值是3，那么B从A获取到时间层值为4，C从B获取到时间，C的层值被置为5。一般只有整个 NTP 系统最顶层的服务器stratum才设为1。\nNTP 同步的方向是从stratum 值较小的节点向较大的节点传播，如果某个 NTP 客户端接收到 stratum 比自己还要大，那么 NTP 客户端认为自己的时间比接受到的时间更为精确，不会进行时间的更新。\n对于大部分 NTP 软件系统来说，服务启动后，stratum 值初始是0，一旦 NTP 服务获取到了时间，NTP 层次就设置为上级服务器 stratum +1。对于具备卫星时钟、原子钟的专业 NTP 设备，一般 stratum 值初始是1。\nNTPD运行过程 NTPD 启动后，stratum 值初始是0，此时 NTPD 接收到 NTP 请求，回复 stratum 字段为0的 NTP 包，客户端接收后，发现 stratum 字段无效，拒绝更新时间，造成时间更新失败。\n几分钟后，NTPD从上级服务器获取到了更新，设置了正确的 stratum，回复 stratum 字段为 n+1的 NTP 包，客户端接收后，确认 stratum 有效，成功进行时间更新。\n在 NTPD 上级服务器不可用的情况下，NTPD 将本机时钟服务模拟为一个上级 NTP 服务器，地址使用环回127.127.1.0。服务启动几分钟后，NTPD 从 127.127.1.0 更新了时钟，设置了有效的 stratum，客户端接收后，成功进行时间更新。\nntpd与ntpdate修改时间的区别 ntpd 不仅仅是时间同步服务器，他还可以做客户端与标准时间服务器进行同步时间，而且是平滑同步，并非ntpdate立即同步，在生产环境中慎用ntpdate，也正如此两者不可同时运行。\n时钟的跃变，对于某些程序会导致很严重的问题。许多应用程序依赖连续的时钟——毕竟，这是一项常见的假定，即，取得的时间是线性的，一些操作，例如数据库事务，通常会地依赖这样的事实：时间不会往回跳跃。不幸的是，ntpdate调整时间的方式就是我们所说的”跃变“：在获得一个时间之后，ntpdate使用settimeofday设置系统时间，这有几个非常明显的问题：\n第一，这样做不安全。ntpdate的设置依赖于ntp服务器的安全性，攻击者可以利用一些软件设计上的缺陷，拿下ntp服务器并令与其同步的服务器执行某些消耗性的任务。由于ntpdate采用的方式是跳变，跟随它的服务器无法知道是否发生了异常（时间不一样的时候，唯一的办法是以服务器为准）。\n第二，这样做不精确。一旦ntp服务器宕机，跟随它的服务器也就会无法同步时间。与此不同，ntpd不仅能够校准计算机的时间，而且能够校准计算机的时钟。\n第三，这样做不够优雅。由于是跳变，而不是使时间变快或变慢，依赖时序的程序会出错（例如，如果ntpdate发现你的时间快了，则可能会经历两个相同的时刻，对某些应用而言，这是致命的）。\n因而，唯一一个可以令时间发生跳变的点，是计算机刚刚启动，但还没有启动很多服务的那个时候。其余的时候，理想的做法是使用ntpd来校准时钟，而不是调整计算机时钟上的时间。\nNTPD 在和时间服务器的同步过程中，会把 BIOS 计时器的振荡频率偏差——或者说 Local Clock 的自然漂移(drift)——记录下来。这样即使网络有问题，本机仍然能维持一个相当精确的走时\nRTC硬件时间相关命令 1 2 3 4 5 clock –r 显示硬件时钟与日期 clock –s 将系统时钟调整为与目前的硬件时钟一致。 clock –w 将硬件时钟调整为与目前的系统时钟一致 查看和修改时间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 查看时间和日期 date date -R timedatectl # 查看本月月历 cal # 修改时区 tzselect # 更改时区为中国 timedatectl set-timezone \u0026#34;Asia/Shanghai\u0026#34; # 设置时间和日期 # 例如：将系统日期设定成2019年11月3日的命令 date -s 11/03/2019 #将系统时间设定成下午5点55分55秒的命令 date -s 17:55:55 # 将当前时间和日期写入BIOS，避免重启后失效** hwclock -w # 或者 clock -w ","date":"2019-06-14T00:15:23+08:00","image":"https://www.lingcoder.com/p/intranet-host-ntp/cover_hudcce0a0c120aae61c393f6578da670d0_3168967_120x120_fill_box_smart1_3.png","permalink":"https://www.lingcoder.com/p/intranet-host-ntp/","title":"内网环境集群主机的时间同步"},{"content":"Kafka集群搭建 使用场景 异步处理： 如用户注册后，发送注册邮件，再发送注册短信。 应用解耦： 如用户下单后，订单系统需要通知库存系统。 流量削峰：如秒杀活动，一般会因为流量过大，导致流量暴增。 日志处理：解决大量日志采集后的传输问题。消息队列负责日志后续处理转发。 消息通讯： 优点 高吞吐量，非常普通的应将kafka也可以支持每秒数百万的消息。\n支持通过kafka服务器和消费机集群来区分消息。\n支持hadoop并行数据加载。\n关键概念： broker: kafka集群中的一台或多台服务器统称broker。\nTopic： kafka处理的消息源（feeds of messages）的不同分类。\npartition：Topic物理机上的分组，一个topic可分为多个partition，每个partition是一个有序的队列。其中的每条消息都会被分配一个有序的id（offset）。\nMessage ：消息，是通信的基本单位。每个producer可以向一个topic（主题）发布一些消息。\nProducers：消息和数据的生产者，向kafka的一个topic发布消息的过程叫producers。\nconsumers：消息和数据消费者，订阅topic并处理其发布的消息的过程叫做consumers。\n安装运行 官网地址：http://kafka.apache.org/downloads\n1. 软件环境 CenOS7/Ubuntu 虚拟机三台。 已经搭建好的zookeeper集群。 软件版本：kafka_2.12-2.2.0 2. 安装步骤 下载官方二进制包 1 wget https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.2.0/kafka_2.12-2.2.0.tgz 解压 1 tar -zxvf kafka_2.12-2.2.0.tgz -C /usr/local/ 修改配置文件 1 vim /usr/local/kafka_2.12-2.2.0/config/server.properties 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 不可重复 # 这是这台虚拟机上的值，在另外两台虚拟机上应该是2或者3， # 这个值是唯一的，每台虚拟机或者叫服务器不能相同 broker.id=1 # 填写本机ip listeners=PLAINTEXT://192.168.137.200:9092 log.retention.hours=24 # 新增下面三项 message.max.byte=5242880 default.replication.factor=2 replica.fetch.max.bytes=5242880 # 设置zookeeper的连接端口,新版本的kafka不再使用zookeeper # 而是通过brokerlist的配置让producer直接连接broker # 这个brokerlist可以配置多个，只要有一个能连接上，就可以让producer获取道集群中的其他broker的信息,绕过了zookeeper zookeeper.connect=192.168.137.1:2181,192.168.137.1:2182,192.168.137.1:2183 3. 启动运行 1 2 3 4 5 # 进入kafka的bin目录 cd /usr/local/kafka_2.12-2.2.0/bin/ # 启动kafka ./kafka-server-start.sh -daemon ../config/server.properties 检测是否启动成功\n1 jps 4. 验证是否创建成功 创建 topic 1 ./kafka-topics.sh --create --zookeeper 192.168.137.1:2181 --replication-factor 2 --partitions 1 --topic my-topic 参数解释：\n--replication-factor 2 // 复制两份 --partitions 1 // 创建1个分区 --topic // 主题为my-topic -- --zookeeper // 此处为为zookeeper监听的地址\n创建生产者 producer 1 2 # IP地址可以写brokerlist中的任意一个 ./kafka-console-producer.sh --broker-list 192.168.137.200:9092 --topic my-topic 此时，console处于阻塞状态，可以直接输入数据。\n创建消费者 consumer 1 2 # 要切换到另一台虚拟机的shell界面输入以下命令 ./kafka-console-consumer.sh --bootstrap-server 192.168.137.100:9092 --topic my-topic --from-beginning 显示所有topic 1 ./kafka-topics.sh --list --zookeeper 192.168.137.1:2181 5. 常用配置详解 broker配置参数 参数 默认值 描述 broker.id -1 每一个boker都有一个唯一的id作为它们的名字。当该服务器的IP地址发生改变时，broker.id没有变化，则不会影响consumers的消息情况 port 9092 broker server服务端口 host.name \u0026quot;\u0026quot; broker的主机地址，若是设置了，那么会绑定到这个地址上，若是没有，会绑定到所有的接口上，并将其中之一发送到ZK log.dirs /tmp/kafka-logs kafka数据的存放地址，多个地址的话用逗号分割,多个目录分布在不同磁盘上可以提高读写性能 /data/kafka-logs-1，/data/kafka-logs-2 message.max.bytes 1000012 表示消息体的最大大小，单位是字节 num.network.threads 3 broker处理消息的最大线程数，一般情况下数量为cpu核数 num.io.threads 8 处理IO的线程数 log.flush.interval.messages Long.MaxValue 在数据被写入到硬盘和消费者可用前最大累积的消息的数量 log.flush.interval.ms Long.MaxValue 在数据被写入到硬盘前的最大时间 log.flush.scheduler.interval.ms Long.MaxValue 检查数据是否要写入到硬盘的时间间隔。 log.retention.hours 168 (24*7) 控制一个log保留多长个小时 log.retention.bytes -1 控制log文件最大尺寸 log.cleaner.enable false 是否log cleaning log.cleanup.policy delete delete还是compat. log.segment.bytes 1073741824 单一的log segment文件大小 log.roll.hours 168 开始一个新的log文件片段的最大时间 background.threads 10 后台线程序 num.partitions 1 默认分区数 socket.send.buffer.bytes 102400 socket SO_SNDBUFF参数 socket.receive.buffer.bytes 102400 socket SO_RCVBUFF参数 zookeeper.connect 指定zookeeper连接字符串， 格式如hostname:port/chroot。chroot是一个namespace zookeeper.connection.timeout.ms 6000 指定客户端连接zookeeper的最大超时时间 zookeeper.session.timeout.ms 6000 连接zk的session超时时间 zookeeper.sync.time.ms 2000 zk follower落后于zk leader的最长时间 -high-level consumer的配置参数 参数 默认值 描述 groupid groupid 一个字符串用来指示一组consumer所在的组 socket.timeout.ms 30000 socket超时时间 socket.buffersize 64*1024 socket receive buffer fetch.size 300 * 1024 控制在一个请求中获取的消息的字节数。 这个参数在0.8.x中由fetch.message.max.bytes,fetch.min.bytes取代 backoff.increment.ms 1000 这个参数避免在没有新数据的情况下重复频繁的拉数据。 如果拉到空数据，则多推后这个时间 queued.max.message.chunks 2 high level consumer内部缓存拉回来的消息到一个队列中。 这个值控制这个队列的大小 auto.commit.enable true 如果true,consumer定期地往zookeeper写入每个分区的offset auto.commit.interval.ms 10000 往zookeeper上写offset的频率 auto.offset.reset largest 如果offset出了返回，则 smallest: 自动设置reset到最小的offset. largest : 自动设置offset到最大的offset. 其它值不允许，会抛出异常. consumer.timeout.ms -1 默认-1,consumer在没有新消息时无限期的block。如果设置一个正值， 一个超时异常会抛出 rebalance.retries.max 4 rebalance时的最大尝试次数 producer的配置参数 参数 默认值 描述 producer.type sync 指定消息发送是同步还是异步。异步asyc成批发送用kafka.producer.AyncProducer， 同步sync用kafka.producer.SyncProducer metadata.broker.list boker list 使用这个参数传入boker和分区的静态信息，如host1:port1,host2:port2, 这个可以是全部boker的一部分 compression.codec NoCompressionCodec 消息压缩，默认不压缩 compressed.topics null 在设置了压缩的情况下，可以指定特定的topic压缩，未指定则全部压缩 message.send.max.retries 3 消息发送最大尝试次数 retry.backoff.ms 300 每次尝试增加的额外的间隔时间 topic.metadata.refresh.interval.ms 600000 定期的获取元数据的时间。当分区丢失，leader不可用时producer也会主动获取元数据，如果为0，则每次发送完消息就获取元数据，不推荐。如果为负值，则只有在失败的情况下获取元数据。 queue.buffering.max.ms 5000 在producer queue的缓存的数据最大时间，仅仅for asyc queue.buffering.max.message 10000 producer 缓存的消息的最大数量，仅仅for asyc queue.enqueue.timeout.ms -1 0当queue满时丢掉，负值是queue满时block,正值是queue满时block相应的时间，仅仅for asyc batch.num.messages 200 一批消息的数量，仅仅for asyc request.required.acks 0 0表示producer无需等待leader的确认，1代表需要leader确认写入它的本地log并立即确认，-1代表所有的备份都完成后确认。 仅仅for sync request.timeout.ms 10000 确认超时时间 Kafka-manager 搭建 下载地址:https://github.com/yahoo/kafka-manager/releases\n1 2 3 4 5 6 # 在线下载 wget https://github.com/yahoo/kafka-manager/archive/2.0.0.2.tar.gz # 解压到 /usr/local tar -zxvf 2.0.0.2.tar.gz -C /usr/local # 修改配置 vim /usr/local/kafka-manager-2.0.0.2/conf/application.conf 编辑配置文件 application.conf 1 2 3 4 5 6 ## 注释这一行，下面添加一行 # kafka-manager.zkhosts=\u0026#34;kafka-manager-zookeeper:2181\u0026#34; ## 根据自己的zookeeper重新配置 kafka-manager.zkhosts=\u0026#34;192.168.137.1:2181,192.168.137.1:2182,192.168.137.1:2183\u0026#34; 启动 Kafka-manager 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 切换到bin目录 cd /usr/local/kafka-manager-2.0.0.2/ # 执行生成zip部署文件 ./sbt clean dist # 打包结束后,提取zip文件并解压到/usr/local unzip /usr/local/kafka-manager-2.0.0.2/target/universal/kafka-manager-2.0.0.2.zip # 移动到/usr/local/ mv kafka-manager-2.0.0.2 /usr/local/kafka-manager # 启动项目 # -Dhttp.port，指定端口,默认端口 9000 # -Dconfig.file=conf/application.conf 指定配置文件: # 切换到目录, cd /usr/local/kafka-manager/bin # 方式1 简单启动 ./bin/kafka-manager # 方式2 指定配置,端口,后台启动 nohup ./kafka-manager -Dconfig.file=../conf/application.conf -Dhttp.port=9000 \u0026amp; ","date":"2019-05-23T12:20:54+08:00","image":"https://www.lingcoder.com/p/kafka-cluster-install-and-config/cover_hu0d4691e1215b462b3636fd340b6d3f75_1623329_120x120_fill_box_smart1_3.png","permalink":"https://www.lingcoder.com/p/kafka-cluster-install-and-config/","title":"Kafka集群搭建"},{"content":"Hyper-V 虚拟机固定 Ip设置 需求来源 忽略外部网络变化，时刻保持虚拟机的 IP 地址不变。\n物理机与虚拟机互访，虚拟机之间互访，虚拟机联网\n设置步骤 固定虚拟机 IP\n以 192.168.137.X 网段，CentOS-7 操作系统为例。查看虚拟机 IP 1 ip addr 得到需要改的网卡信息后，编辑配置文件 1 2 cd /etc/sysconfig/network-scripts vim ifcfg-eth0 添加下面几行\n1 2 3 4 5 6 7 8 BOOTPROTO=\u0026#34;static\u0026#34; DEVICE=\u0026#34;eth0\u0026#34; ONBOOT=\u0026#34;yes\u0026#34; IPADDR=\u0026#34;192.168.137.200\u0026#34; GATEWAY=\u0026#34;192.168.137.1\u0026#34; DNS1=\u0026#34;114.114.114.114\u0026#34; DNS2=\u0026#34;114.114.115.115\u0026#34; NETMASK=\u0026#34;255.255.255.0\u0026#34; 重启网络，使设置生效 1 systemctl restart network 如果是 Ubuntu 18.04,修改方式如下：\n1 2 # 编辑 *-cloud-init.yaml 文件,我这里为50-cloud-init.yaml sudo vim /etc/netplan/50-cloud-init.yaml 配置文件修改如下：\n1 2 3 4 5 6 7 8 9 10 network: ethernets: eth0: addresses: [192.168.137.200/24] gateway4: 192.168.137.1 dhcp4: false nameservers: addresses: [114.114.114.114] version: 2 1 2 # 生效 sudo netplan apply 打开Hyper-V，点击虚拟机交换管理器 打开 Hyper-V，选中虚拟机列表，鼠标右击打开设置： 点击左侧网络适配器后，勾选刚才设置的Centos-server保存 打开网络设置，点击“更改适配器选项”，找到刚才我们设置生成的新虚拟网卡CentOS-server,右击选择属性。打开后再点击Internet协议版本4（TCP/IP）： 在打开后的设置框如下图一样设置： 虚拟机联网\n","date":"2019-05-10T12:20:54+08:00","image":"https://www.lingcoder.com/p/hyper-v-fixed-ip/cover_hue05632b6ed638f2839f55fc1f9ab6cef_2339700_120x120_fill_box_smart1_3.png","permalink":"https://www.lingcoder.com/p/hyper-v-fixed-ip/","title":"Hyper-V虚拟机固定Ip设置"},{"content":"Git的官方网站：http://git-scm.com\nGit和GitHub使用总结 一、GIT初始化设置： 创建密钥 1 ssh‐keygen ‐t rsa ‐C \u0026#34;lingcoder@gmail.com\u0026#34; 远程仓库 1 2 3 4 5 6 7 8 添加远程origin库关联 git remote add origin git@github.com:lingcoder/xxx.git 查看远程仓库 git remote -v 删除远程origin库的关联 git remote rm origin 用户名邮箱配置 全局配置\n1 2 3 git config --global user.name \u0026#34;lingcoder\u0026#34; git config --global user.email \u0026#34;lingcoder@gmail.com\u0026#34; git config --list 项目单独配置（在项目根目录下）\n1 2 3 git config user.name \u0026#34;lingcoder\u0026#34; git config user.email \u0026#34;lingcoder@gmail.com\u0026#34; git config --list 设置Git默认分支名为 main 1 git config --global init.defaultBranch main 创建本地仓库 1 git init Clone远程仓库 1 git clone 项目地址 格式化与空白 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 1. 问题来源： Windows使用回车和换行两个字符来结束一行，而Mac和Linux只使用换行一个字符 2. 换行定义： CR Carriage-Return的缩写： 回车(CR, ASCII 13, \\r) LF Line-Feed的缩写，换行(LF, ASCII 10, \\n) window 采用CRLF Linux，Mac采用LF 3. 解决办法： (0) Git配置 Git可以在你提交代码时自动地把行结束符CRLF转换成LF，而在检出代码时把LF转换成CRLF ⑴ 在Windows系统上与其他系统协作开发 用core.autocrlf来打开此项功能，如果是在Windows系统上，把它设置成true，这样当检出 代码时，LF会被转换成CRLF： $ git config --global core.autocrlf true ⑵ 在Linux或Mac系统上与其他系统协作开发 Linux或Mac系统使用LF作为行结束符，如果你不想Git在检出代码时进行自动的转换，把core.autocrlf设置成input来告诉Git在提交代码时把CRLF转换成LF，检出时不转换： $ git config –-global core.autocrlf input 这样在Windows系统上检出的代码会保留CRLF；而在Mac和Linux系统上，以及仓库中保留LF。 ⑶ 团队都是在Windows系统上开发 如果在Windows系统上开发程序，且正在开发仅运行在Windows上的项目，可以设置false取消此功能，把回车符记录在库中： $ git config –-global core.autocrlf false 代理设置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 查看全局代理设置 git config --global http.proxy 设置http,https,socket代理 以`127.0.0.1:1080`为例 git config --global http.proxy \u0026#39;http://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;http://127.0.0.1:1080\u0026#39; git config --global http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; 需要代理用户名密码的情况,以http为例 git config http.proxy http://username:password@127.0.0.1:1080 忽略SSL证书错误 git config --global http.sslVerify false 删除 proxy git config --global --unset http.proxy git config --global --unset https.proxy 自定义操作 1 2 3 4 5 6 7 8 9 10 #让Git显示颜色，会让命令输出看起来更醒目 git config ‐‐global color.ui true #自定义git命令，以简化\u0026#34;git status\u0026#34;成\u0026#34;git st\u0026#34;为例 git config ‐‐global alias.st status #自定义日志颜色 git config ‐‐global alias.lg \u0026#34;log ‐‐color ‐‐graph ‐‐pretty=format:\u0026#39;%Cred%h%Creset ‐%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset\u0026#39; ‐‐abbrev‐commit\u0026#34; git lg 更新单个文件 1 2 3 4 5 6 更新本地 git checkout -- \u0026#34;[文件路径]/[文件名]\u0026#34; 更新远程 git fetch git checkout origin/master -- \u0026#34;\u0026#34;[文件路径]/[文件名]\u0026#34;\u0026#34; 二、GIT基本操作 添加到暂存区区 1 2 3 4 5 6 7 8 9 10 11 表示添加所有内容 git add -A 表示添加新文件和编辑过的文件不包括删除的文件 git add . 表示添加编辑或者删除的文件，不包括新添加的文件 git add -u 强制添加一个被.gitignore文件忽略的文件的版本库 git add ‐f [文件名] 提交 1 2 3 4 5 6 普通提交 git commit` 将本次提交的内容合并到上次提交 git commit --amend 删除 1 2 从版本库删除某个文件 git rm [文件名] 版本回退 1 2 3 4 5 6 7 8 撤回到某个版本 git reset --hard [提交ID] 查看过去的提交历史 git log 查看所有的提交历史 git reflog 撤销修改 1 2 3 4 5 让file回到最近一次 \u0026#34;git commit\u0026#34; 或 \u0026#34;git add\u0026#34; 时的状态 git checkout -- [文件名] 可以把暂存区的file修改撤销掉（unstage），重新放回工作区 git reset HEAD [文件名] 三、GIT分支操作 创建分支 1 2 3 4 5 6 7 8 9 10 11 12 13 14 创建一个dev分支并且切换到dev分支 git checkout ‐b dev 创建dev分支 git branch dev 切换到dev分支 git checkout dev 创建远程origin的dev分支到本地 git checkout ‐b dev origin/dev 查看分支 git branch 分支命名规范： issue-100 bug修复分支 feature-sms sms功能分支\n分支合并 1 2 3 4 5 合并dev到当前的分支 git merge dev 合并分支，并且禁用 Fast forward git merge ‐‐no‐ff ‐m \u0026#34;merge with no‐ff\u0026#34; dev Fast forward模式： Git在merge时生成一个新的commit，以便于从分支历史上就可以看出合并分支信息\n分支推送 1 2 3 4 5 6 7 8 9 10 将当前master分支推送到远程,并设置关联 git push ‐u origin master 强制推送dev分支到远程 git push origin dev -f 取出远程dev分支 git fetch origin dev 将当前分支内容重置为取出的dev分支 git reset --hard origin dev 分支绑定 1 2 3 4 5 将本地的dev分支和远程的origin的dev分支绑定 git branch ‐‐set‐upstream-to=origin/dev dev 以后就可以直接pull了 git pull 分支删除 1 2 3 4 5 6 7 8 删除dev分支 git branch ‐d dev 强行删除 git branch ‐D dev 修剪远程分支 git fetch -p stash功能 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 把当前的工作状态保存下来，以便于后面恢复，包括index区。 git stash 把当前的工作状态保存下来，以便于后面恢复，包括index区。 git stash list 恢复statsh内容，但是不删除statsh git stash apply 恢复指定的stash git stash apply stash@{0} 删除stash内容 git stash drop 恢复同时删除stash内容 git stash pop 四、GIT标签操作 本地操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 查看分支 git tag 给当前分支打标签 git tag 给某个提交打标签 git tag [标签名] [提交ID] 创建带有说明的标签，用 -a 指定标签名， -m 指定说明文字 git tag ‐a [标签名] ‐m \u0026#34;第一个正式版本\u0026#34; [提交ID] 查看标签说明 git show [标签名] 删除标签 git tag -d [标签名] 远程操作 1 2 3 4 5 6 7 8 9 10 11 标签推送 git push origin [标签名] 推送全部尚未推送到远程的本地标签： git push origin ‐‐tags 删除远程标签 1. 先删除本地标签 git tag -d [标签名] 2. 再推送远程 git push origin :refs/tags/[标签名] 五、Github同步原作者代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 1. 查看远程状态 git remote -v 2. 添加原作者的远程仓库到remote git remote add upstream 原作者远程仓库地址 3. 同步fork git fetch upstream 4. 切换到本地主分支 git checkout master 5. 把 upstream/master 分支合并到本地 master git merge upstream/master 6. push到远程仓库 git push origin master 7. 解决冲突 直接编辑冲突文件，然后提交更改重新push即可 六、GIT多人协作的工作模式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 1. 首先，试图推送自己的修改 git push origin branch-name 2. 如果推送失败，则因为远程分支比你的本地更新，需先试图合并 git pull 3. 如果合并有冲突，则解决冲突，并在本地提交 4. 没有冲突或者解决掉冲突后，再推送就能成功！ git push origin branch-name 如果\u0026#34;git pull\u0026#34;提示“no tracking information”，则先命令绑定关系 git branch --set-upstream branch-name origin/branch-name # 日常使用顺序 # 去自己的工作分支 $ git checkout work 工作 .... 提交工作分支的修改 $ git commit -a 回到主分支 $ git checkout master 获取远程最新的修改，此时不会产生冲突 $ git pull 回到工作分支 $ git checkout work 用rebase合并主干的修改，如果有冲突在此时解决 $ git rebase master 回到主分支 $ git checkout master 合并工作分支的修改，此时不会产生冲突。 $ git merge work 提交到远程主干 $ git push 七、GIT关联Gitee和GitHub 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 1. 删除已有的默认远程库： git remote rm origin 2. 关联码云的远程库 git remote add [远程库别名] git@gitee.com:xxx/xxx.git 3. 关联GitHub远程库 git remote add [远程库别名] git@github.com:xxx/xxx.git 4. 查看远程库信息 git remote ‐v 5. 分别推送到github和gitee 以别名github为例，推送到GitHub，使用命令： git push github master 以别名gitee为例，推送到码云，使用命令： git push gitee master 至此，我们的本地库就可以同时与多个远程库互相同步 八、Github 解决敏感配置文件上传问题 将真正的config文件加入.gitignore，然后推送一个基本的config_example文件 push 结束后，再把 config_example 添加到 .gitignore 中。 经典情景： 别人先clone 你的项目，把 config_example 文件 pull 下来后，复制一份再重命名为config，根据自己的环境稍加修改config文件。然后把两文件都添加到.gitignore 中。以后push 则不会再对远程仓库造成影响。 九、.gitignore文件忽略原则 忽略文件的原则 1 2 3 1. 忽略操作系统自动生成的文件，比如缩略图等； 2. 忽略编译生成的中间文件、可执行文件等； 3. 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 检查文件忽略情况 1 git check‐ignore ‐v [文件名] 十、搭建git私服，以ubuntu为例 基本使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1. 安装git： sudo apt-get install git 2. 创建一个git用户，用来运行git服务： sudo adduser git 3. 创建证书登录： 收集员工公钥`id_rsa.pub`文件，导入到`/home/git/.ssh/authorized_keys`文件里，一行一个。 4. 初始化Git仓库： 选定目录作为Git仓库，假定是`/srv/sample.git`，在`/srv`目录下输入命令： sudo git init --bare sample.git 5. 把owner改为`git` sudo chown -R git:git sample.git 6. 禁用shell登录： 编辑`/etc/passwd`文件 git:x:1001:1001:,,,:/home/git:/bin/bash 改为： git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell 7. 克隆远程仓库： git clone git@server:/srv/sample.git 十一、利用git管理svn 简单介绍 GIT自带的git svn命令可以用来管理svn项目，对于习惯使用git的人来说，是一个不错的选择。基本上除了检出，提交，更新代码命令有所区别，大部分都是纯git操作\n常用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 检出svn仓库代码 git svn clone ## 例子1 将dapp-parent项目检出到当前目录，文件夹名称dapp-parent git svn clone http://xxx/dapp-parent ## 例子2 将dapp-parent项目检出到当前目录，文件夹名称huizhong git svn clone http://xxx/dapp-parent huizhong # 更新svn仓库的代码到本地当前分支 git svn rebase # 提交本地分支的代码到svn仓库 git svn dcommit # 查看git管理的svn仓库信息 git svn info # 提交git分支到svn分支仓库（需要额外配置，并不常用） git svn tag 十二、日志提交规范(参考 Angularjs 提交规范) build: 影响构建系统或外部依赖关系的更改（示例范围：gulp，broccoli，npm）\nci: 更改我们的持续集成文件和脚本（e.g.: Travis，GitLab 等）\ndocs: 仅文档更改\nfeat: 一个新功能\nfix: 修复错误\nperf: 改进性能的代码更改\nrefactor: 代码更改，既不修复错误也不添加功能\nstyle: 不影响代码含义的变化（空白，格式化，缺少分号等）\ntest: 添加缺失测试或更正现有测试\nchore: 构建过程或辅助工具的变动\nrelease: 版本发布\nrevert: 特殊情况，当前 commit 用于撤销以前的 commit\n示例\n1 2 3 4 5 docs(core): Update inject error documentation(#123) build: update eslint dependencies to v5.32.0 (#47016) fix(router): do not call preload method when not necessary (#47007) feat(language-service): support fix the component missing member (#46764) refactor(common): Align PathLocationStrategy constructor(#123) 十三、将误传至Github的敏感资料删除 1 2 3 4 5 6 7 8 9 10 11 git filter-branch --force --index-filter \u0026#39;git rm --cached --ignore-unmatch [敏感文件路径]\u0026#39; --prune-empty --tag-name-filter cat -- --all git push origin [分支名称] --force rm -rf .git/refs/original/ git reflog expire --expire=now --all git gc --prune=now git gc --aggressive --prune=now 扩展使用 管理公钥 Gitosis 管理权限 Gitolite ","date":"2019-01-01T14:13:54+08:00","image":"https://www.lingcoder.com/p/git-and-github-summary/cover_hub20bbea5694ca3a59339a693ae8ca887_67445_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.lingcoder.com/p/git-and-github-summary/","title":"Git和GitHub使用总结"},{"content":"简说设计模式-单例模式 单例模式 核心作用 : 保证一个类只有一个实例，并且提供一个访问该实例的全局访问点。 应用场景： 网站计数器 数据库连接池的设计 Spring容器 等等 模式优点: – 由于单例模式只生成一个实例，减少了系统性能开销，当一个对象的产生需要 比较多的资源时，如读取配置、产生其他依赖对象时，则可以通过在应用启动 时直接产生一个单例对象，然后永久驻留内存的方式来解决 – 单例模式可以在系统设置全局的访问点，优化环共享资源访问，例如可以设计 一个单例类，负责所有数据表的映射处理 常见实现： 主要: 1. 饿汉式 描述: static变量会在类装载时初始化，由虚拟机保证单线程,可以省略synchronized关键字。 优点: 线程安全，调用效率高。 缺点: 不能延时加载;若只加载本类，而未调用getInstance()，则造成资源浪费！ 示例:\n1 2 3 4 5 6 7 public class SingletonHungry { private static SingletonHungry instance = new SingletonHungry(); private SingletonHungry(){} // 私有化构造器 public static SingletonHungry getInstance(){ return instance; } } 2. 懒汉式 描述:\n优点: 线程安全，调用效率不高。 但是，有利于资源利用;可以延时加载。 缺点：每次调用getInstance()方法同步，并发效率较低。\n示例:\n1 2 3 4 5 6 7 8 9 10 public class SingletonLazy { private static instance; private SingletonLazy(){} // 私有化构造器 public static synchronized SingletonLazy getInstance(){ if(instance == null){ instace = new SingletonLzay(); } return instance; } } 其他： 3. 双重检测锁式 描述: 将同步内容放到if内部,提高效率,仅第一次未创建时需要同步\n缺点: 由于JVM底层内部模型原因，偶尔会出问题。不建议使用\n示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class Singleton { private static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if (instance == null) { Singleton sc; synchronized (Singleton.class) { sc = instance; if (sc == null) { synchronized (Singleton.class) { if (sc == null) { sc = new Singleton(); } } instance = sc; } } } return instance; } } 4. 静态内部类式 描述: 外部类没有静态属性, 静态内部类只在被调用时才会加载。类加载是线程安全的。 同时static final保证了内存中唯一实例存在且只能被赋值一次，保证了线程安全性.\n优点: 线程安全，调用效率高，可以延时加载.\n缺点: (反射和反序列化可破解以上几种单例实现方式)\n示例:\n1 2 3 4 5 6 7 8 9 10 public class Singleton { private Singleton() { } private static class SingletonInnerClass { private static final Singleton instance = new Singleton(); } public static Singleton getInstance() { return SingletonInnerClass.instance; } } 5. 枚举单例 描述: 枚举本身就是单例模式。由JVM从根本上提供保障！避免通过反射和反序列化的漏洞！\n优点: 线程安全，实现简单.\n缺点: 不能延时加载.\n示例:\n1 2 3 4 5 6 7 8 9 public enum SingletonEnum{ // 定义一个枚举的元素，代表SingletonEnum 的一个实例。 INSTANCE; // 单例可以有自己的操作 public void whateverMethod(){ // 功能处理 } } 选择推荐: 单例对象 占用 资源 少，不需要 延时加载： 枚举式 好于 饿汉式\n单例对象 占用 资源 大，需要 延时加载： 静态内部类式 好于 懒汉式\n","date":"2019-01-01T12:20:54+08:00","image":"https://www.lingcoder.com/p/mysql-master-slave-sync-summary/cover_huc2e1cc772a3cda51be6ac9ae7b3f4f86_358854_120x120_fill_box_smart1_3.png","permalink":"https://www.lingcoder.com/p/mysql-master-slave-sync-summary/","title":"MySQL主从同步总结"},{"content":"简说设计模式-单例模式 单例模式 核心作用 : 保证一个类只有一个实例，并且提供一个访问该实例的全局访问点。 应用场景： 网站计数器 数据库连接池的设计 Spring容器 等等 模式优点: – 由于单例模式只生成一个实例，减少了系统性能开销，当一个对象的产生需要 比较多的资源时，如读取配置、产生其他依赖对象时，则可以通过在应用启动 时直接产生一个单例对象，然后永久驻留内存的方式来解决 – 单例模式可以在系统设置全局的访问点，优化环共享资源访问，例如可以设计 一个单例类，负责所有数据表的映射处理 常见实现： 主要: 1. 饿汉式 描述: static变量会在类装载时初始化，由虚拟机保证单线程,可以省略synchronized关键字。 优点: 线程安全，调用效率高。 缺点: 不能延时加载;若只加载本类，而未调用getInstance()，则造成资源浪费！ 示例:\n1 2 3 4 5 6 7 public class SingletonHungry { private static SingletonHungry instance = new SingletonHungry(); private SingletonHungry(){} // 私有化构造器 public static SingletonHungry getInstance(){ return instance; } } 2. 懒汉式 描述:\n优点: 线程安全，调用效率不高。 但是，有利于资源利用;可以延时加载。 缺点：每次调用getInstance()方法同步，并发效率较低。\n示例:\n1 2 3 4 5 6 7 8 9 10 public class SingletonLazy { private static instance; private SingletonLazy(){} // 私有化构造器 public static synchronized SingletonLazy getInstance(){ if(instance == null){ instace = new SingletonLzay(); } return instance; } } 其他： 3. 双重检测锁式 描述: 将同步内容放到if内部,提高效率,仅第一次未创建时需要同步\n缺点: 由于JVM底层内部模型原因，偶尔会出问题。不建议使用\n示例:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class Singleton { private static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if (instance == null) { Singleton sc; synchronized (Singleton.class) { sc = instance; if (sc == null) { synchronized (Singleton.class) { if (sc == null) { sc = new Singleton(); } } instance = sc; } } } return instance; } } 4. 静态内部类式 描述: 外部类没有静态属性, 静态内部类只在被调用时才会加载。类加载是线程安全的。 同时static final保证了内存中唯一实例存在且只能被赋值一次，保证了线程安全性.\n优点: 线程安全，调用效率高，可以延时加载.\n缺点: (反射和反序列化可破解以上几种单例实现方式)\n示例:\n1 2 3 4 5 6 7 8 9 10 public class Singleton { private Singleton() { } private static class SingletonInnerClass { private static final Singleton instance = new Singleton(); } public static Singleton getInstance() { return SingletonInnerClass.instance; } } 5. 枚举单例 描述: 枚举本身就是单例模式。由JVM从根本上提供保障！避免通过反射和反序列化的漏洞！\n优点: 线程安全，实现简单.\n缺点: 不能延时加载.\n示例:\n1 2 3 4 5 6 7 8 9 public enum SingletonEnum{ // 定义一个枚举的元素，代表SingletonEnum 的一个实例。 INSTANCE; // 单例可以有自己的操作 public void whateverMethod(){ // 功能处理 } } 选择推荐: 单例对象 占用 资源 少，不需要 延时加载： 枚举式 好于 饿汉式\n单例对象 占用 资源 大，需要 延时加载： 静态内部类式 好于 懒汉式\n","date":"2018-01-01T12:20:54+08:00","image":"https://www.lingcoder.com/p/java-design-patterns-singleton/cover_huf13e842be3d82caf112c9c2c54c6ca11_97904_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.lingcoder.com/p/java-design-patterns-singleton/","title":"简谈Java设计模式-单例模式"},{"content":"日志切割 安装 cronolog 安装 1 2 3 4 5 6 7 # 下载cronolog-1.6.2.tar.gz 并解压 wget http://cronolog.org/download/cronolog-1.6.2.tar.gz # 解压 tar zxvf cronolog-1.6.2.tar.gz # 编译安装 cd cronolog-1.6.2 ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 验证安装\n1 2 3 4 # 验证是否安装成功 which cronolog # 显示以下信息则成功 # /usr/local/sbin/cronolog 修改 Tomcat 8 配置 替换 tomcat 目录下 /bin/Catalina.sh 文件内容 1 2 3 4 5 if [ -z \u0026#34;$CATALINA_OUT\u0026#34; ] ; then CATALINA_OUT=日志路径/catalina.out fi 为\n1 2 3 4 5 if [ -z \u0026#34;$CATALINA_OUT\u0026#34; ] ; then CATALINA_OUT=日志路径/catalina.%Y-%m-%d.out fi 注释掉 touch \u0026quot;$CATALINA_OUT\u0026quot; 1 #touch \u0026#34;$CATALINA_OUT\u0026#34; 替换（共有两处修改） 1 2 org.apache.catalina.startup.Bootstrap \u0026#34;$@\u0026#34; start \\ \u0026gt;\u0026gt; \u0026#34;$CATALINA_OUT\u0026#34; 2\u0026gt;\u0026amp;1 \u0026amp; 为\n1 2 org.apache.catalina.startup.Bootstrap \u0026#34;$@\u0026#34; start 2\u0026gt;\u0026amp;1 \\ | /usr/local/sbin/cronolog \u0026#34;$CATALINA_OUT\u0026#34; \u0026gt;\u0026gt; /dev/null \u0026amp; 重启 tomcat 即可。\n定时删除 新建 xxx.sh 文件，添加内容如下： 1 2 3 4 #!/bin/sh find /usr/local/apache-tomcat-8.5.15/logs/ -mtime +1 -name \u0026#34;*.out\u0026#34; -exec rm -rf {} \\; find /usr/local/apache-tomcat-8.5.15/logs/ -mtime +1 -name \u0026#34;*.log\u0026#34; -exec rm -rf {} \\; find /usr/local/apache-tomcat-8.5.15/logs/ -mtime +1 -name \u0026#34;*.txt\u0026#34; -exec rm -rf {} \\; 执行 crontab -e 命令打开定时任务配置文件，在里面录入 1 10 0 * * * sh 目录/xxx.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 定时任务cron命令示例： 1 2 3 4 * * * * * # 每隔一分钟执行一次任务 0 * * * * # 每小时的0点执行一次任务，比如6:00，10:00 6,10 * 2 * * # 每个月2号，每小时的6分和10分执行一次任务 */3,*/5 * * * * # 每隔3分钟或5分钟执行一次任务，比如10:03，10:05，10:06 ","date":"2017-10-17T09:02:06+08:00","permalink":"https://www.lingcoder.com/p/tomcat8-log-splitter/","title":"Tomcat8日志切割和定期删除"},{"content":"Zookeeper安装和配置 准备工作 安装 JDK,此步略。\n下载 zookeeper\n1 2 3 wget http://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz # 或者 curl -O https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz 解压 zookeeper\n1 tar -zxvf zookeeper-3.4.6.tar.gz -C /usr/local/ 创建软链,方便版本转换\n1 ln -s zookeeper-3.4.6 zookeeper 单机版安装 切换到 zookeer 软链目录下执行\n1 cd usr/local/zookeeper/conf/cp zoo_sample.cfg zoo.cfg 编辑 zoo.cfg 配置文件\n1 vim zoo.cfg 启动服务\n1 2 3 4 # 启动服务 bin/zkServer.sh start # 测试连接 bin/zkCli.sh –server 127.0.0.1:2181 集群安装 ​\t在zoo.cfg 添加配置,并按照下面的配置部署到相应的机器上,并在相应的服务器的数据目录下创建 myid 文件,并填写本机对应的 server.NUM 数值.如 server.1,则填 1。\n1 2 3 4 5 6 7 8 ## 真集群示例 server.1=192.168.137.101:2888:3888 server.2=192.168.137.102:2888:3888 server.3=192.168.137.103:2888:3888 ## 伪集群示例 # server.1=127.0.0.1:2888:3888 # server.2=127.0.0.1:2889:3889 # server.3=127.0.0.1:2890:3890 配置文件详解 Zookeeper 的默认配置文件为 zookeeper/conf/zoo_sample.cfg，需要将其修改为 zoo.cfg。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ## CS通信心跳数 ## Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，以毫秒为单位。 tickTime=2000 ## 初始通信时限 ## 集群中的follower与leader之间初始连接时能容忍的最多心跳数（tickTime的数量）。 initLimit=10 ## LF同步通信时限 ## 集群中的follower与leader之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。 syncLimit=5 ## 数据文件目录 ## 保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里。 dataDir=/home/ling/zookeeper/data ## 日志文件目录 ## 保存日志文件的目录。 dataLogDir=/home/ling/zookeeper/log ## 客户端连接端口 ## 客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 clientPort=2181 ## 服务器名称与地址：集群信息（服务器编号，服务器地址，LF通信端口，选举端口） ## 这个配置项的书写格式比较特殊，规则如下： ## 如 server.N=YYY:A:B ## N 表示服务器编号； ## YYY 表示服务器的IP地址； ## A为LF通信端口表示该服务器与集群中的leader交换的信息的端口； ## B为选举端口，表示选举新leader时服务器间相互通信的端口（当leader挂掉时，其余服务器会相互通信，选择出新的leader） ## 一般来说，集群中每个服务器的A端口都是一样，每个服务器的B端口也是一样。但是当所采用的为伪集群时，IP地址都一样，只能时A端口和B端口不一样 ## 真集群示例 server.1=192.168.101:2888:3888 server.2=192.168.102:2888:3888 server.3=192.168.103:2888:3888 ## 伪集群示例 # server.1=127.0.0.1:2888:3888 # server.1=127.0.0.1:2889:3889 # server.1=127.0.0.1:2890:3890 ## 最大请求堆积数 ## 默认是1000。在 server 无空闲来处理更多的客户端请求时，允许客户端将请求提交到服务器上来，以提高吞吐性能。当然，为了防止Server内存溢出，这个请求堆积数还是需要限制下的。 # globalOutstandingLimit=1000 ## 预先开辟磁盘空间 ## 用于后续写入事务日志。默认是64M，每个事务日志大小就是64M。如果ZK的快照频率较大的话，建议适当减小这个参数 # preAllocSize=65536 ## 快照 ## 每进行snapCount次事务日志输出后，触发一次快照(snapshot), 此时，ZK会生成一个snapshot.*文件，同时创建一个新的事务日志文件log.*。默认是100000.（真正的代码实现中，会进行一定的随机数处理，以避免所有服务器在同一时间进行快照而影响性能） # snapCount=100000 ## 用于记录所有请求的log，一般调试过程中可以使用，但是生产环境不建议使用，会严重影响性能 # traceFile= ## session 超时时间，单位为毫秒 ## 默认值分别为2和20，即tickTime的2倍和20倍 # minSessionTimeout=2 # maxSessionTimeout=20 ## 不支持以系统属性方式配置 ## 从Socket层面限制单个客户端与单台服务器之间的并发连接数，即以ip地址来进行连接数的限制。如果设置为0，表示不做任何限制。仅仅是单台客户端与单个Zookeeper服务器连接数的限制，不能控制所有客户端的连接数总和 # maxClientCnxns=60 ## 单位为字节 ## 配置单个数据节点上可以存储的最大数据量大小。在变更该参数时，需要变更集群中所有机器以及客户端上均设置才能生效。 # jute.maxbuffer=1048575 ## 单位为字节，仅支持系统属性方式配置：jute.maxBuffer。用于配置单个数据节点上可以存储的最大数据量大小。在变更该参数时，需要变更集群中所有机器以及客户端上均设置才能生效。 # clientPortAddress= ## 默认值为3，不支持以系统属性方式配置。用于配置Zookeeper在自动清理的时候需要保留的快照数据文件数量和对应的事务日志文件。此参数的最小值为3，如果配置的值小于3会自动调整到3。 # autopurge.snapRetainCount=3 ## 默认值为0，单位为小时，不支持以系统属性方式配置。用于配置Zookeeper进行历史文件自动清理的频率。如果配置为0或负数，表示不需要开启定时清理功能。 autopurge.purgeInterval=1 ## 最大保留文件的个数，搭配 autopurge.purgeInterval 使用 autopurge.snapRetainCount=3 ## 默认值为1000，单位为毫秒，仅支持系统属性方式配置 ## 配置Zookeeper进行事务日志fsync操作时消耗时间的报警阈值。一旦fsync操作消耗的时间大于该参数指定的值，就在日志中打印出报警日志 # fsync.warningthresholdms=1000 ## 默认值为yes，可配置项为“yes”和“no”，仅支持系统属性方式配置 ##配置Zookeeper服务器是否在提交的时候，将日志写入操作强制刷入磁盘，默认情况下，每次事务日志写入操作都会实时刷入磁盘，如果设置为“no”，则能一定程度的提高ZooKeeper的写性能，但会存在类似机器断电等安全风险。 ## forceSync=yes ## 默认值为yes，可选配置项为“yes”和“no”，仅支持系统属性方式配置 ## 用于配置Leader服务器是否能够接受客户端的连接，即是否允许Leader向客户端提供服务。默认情况下，Leader服务器能够接受并处理客户端的所有读写请求。在Zookeeper的架构设计中，Leader服务器主要用来进行对事务更新 # leaderServes=yes ## 默认值为no，可选配置项为“yes”和“no”,仅支持系统属性方式配置 ## 用于配置ZooKeeper服务器是否跳过ACL权限检查，默认情况下，会对每一个客户端请求进行权限检查。如果设置为“yes”，则能一定程度的提高ZooKeeper的读写性能，但同时也将向所有客户端开放Zookeeper的数据，包括之前设置过ACL权限的数据节点，也不在接受权限控制 # skipAcl=no ## 默认值为5000，单位毫秒，仅支持系统属性方式配置 ## 配置在Leader选举过程中各服务器之间进行TCP连接创建的超时时间 # cnxTimeout=5000 ","date":"2017-05-14T00:15:23+08:00","image":"https://www.lingcoder.com/p/zookeeper-install-and-config/cover_hue44eb49752b2147242f08fe6938f2d17_3441507_120x120_fill_box_smart1_3.png","permalink":"https://www.lingcoder.com/p/zookeeper-install-and-config/","title":"Zookeeper安装和配置"}]